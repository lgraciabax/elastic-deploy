input {
  file {
    path => "/usr/share/logstash/data/carrito.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
    separator => ","
    columns => ["id", "userId", "dateCreated", "cartItemId", "productId", "quantity"]
  }
  
  # Agrupar los ítems del carrito por el ID del carrito
  aggregate {
    task_id => "%{id}"
    code => "
      map['cartItems'] ||= []
      map['cartItems'] << {
        'id' => event.get('cartItemId'),
        'cartId' => event.get('id'),
        'productId' => event.get('productId'),
        'quantity' => event.get('quantity')
      }

      # Establecer otros atributos del carrito
      map['id'] = event.get('id')
      map['userId'] = event.get('userId')
      begin
        if event.get('dateCreated')
          date_created = Date.strptime(event.get('dateCreated'), '%Y-%m-%d')
          map['dateCreated'] = date_created.to_s
        end
      rescue => e
        event.tag('_dateparsefailure')
        map['dateCreated_parse_error'] = e.message
      end

      # Descartar el evento original, ya que estamos construyendo un nuevo evento agregado
      event.cancel()
    "
    push_previous_map_as_event => true
    timeout => 30 # Ajustar según sea necesario
  }

  

  # Eliminar campos innecesarios
  mutate {
    remove_field => ["cartItemId", "productId", "quantity", "message", "host", "path"]
  }
}


output {
  elasticsearch {
    hosts => ["192.168.100.6:9200"]
    index => "carrito"
    user => "elastic"
    password => "elastic"
  }
}
